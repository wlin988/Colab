{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GymRendering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlin988/Colab/blob/master/GymRendering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XDvssQd64Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5esgX013vPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hduNGfLtA9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "042920d1-5f89-4af2-e0ce-8c8c32f05de9"
      },
      "source": [
        "!pip install pyglet==v1.3.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyglet==v1.3.2 in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==v1.3.2) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbi2xaFo31Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGqXqJxoAsHG",
        "colab_type": "code",
        "outputId": "feb15439-f799-4d9d-fa0b-37fa58fbc971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1013'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1013'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L4YayzR4FYj",
        "colab_type": "code",
        "outputId": "e2da0f5c-3917-43c2-c3cb-f5483362962f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "env.reset()\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "for i in range(99):\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  \n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  if done:\n",
        "    break\n",
        "    \n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoantCmXAtSN",
        "colab_type": "code",
        "outputId": "25f4940b-3b1e-466e-e1a0-604ffc517bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "display.stop()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1005'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x300x24', ':1005'] oserror=None return_code=0 stdout=\"\" stderr=\"\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONXKsqqIxPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1d5f20e7-a546-48b0-993f-e6e25b573e95"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu75/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu75/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu75/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (397.4MB)\n",
            "\u001b[K     |████████████████████████████████| 397.4MB 59.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.16.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "\u001b[31mERROR: torchvision 0.4.1+cu100 has requirement torch==1.3.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.58 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.3.0\n",
            "    Uninstalling torch-1.3.0:\n",
            "      Successfully uninstalled torch-1.3.0\n",
            "Successfully installed torch-0.3.0.post4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEfi4amvJU5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "a04244bb-ea6a-4d4f-abf2-c48a2d794611"
      },
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.1+cu100)\n",
            "Collecting torch==1.3.0 (from torchvision)\n",
            "  Using cached https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.5)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84fjXWXcKMiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82d0f287-f7a5-4d2d-8679-28274874c8d6"
      },
      "source": [
        "!conda install pytorch torchvision -c pytorch"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqNQX27vLMHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFebeakZLVVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size    = 784   # The image size = 28 x 28 = 784\n",
        "hidden_size   = 500   # The number of nodes at the hidden layer\n",
        "num_classes   = 10    # The number of output classes. In this case, from 0 to 9\n",
        "num_epochs    = 8     # The number of times entire dataset is trained\n",
        "batch_size    = 100   # The size of input data took for one iteration\n",
        "learning_rate = 1e-3  # The speed of convergence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA0suBKYLXCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "41b68e78-dad5-4cd2-b20f-5ef6cb206d94"
      },
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:04, 2106966.09it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 55654.12it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:04, 342183.57it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 21574.61it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkOtlSA3LgSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LiTZXvILlAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
        "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
        "    \n",
        "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhtecgDALmh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net(input_size, hidden_size, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7pUcrRSLqAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j06AD0VLuBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoP6lp3VLxgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPxbBQ84L0_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "c50c946d-aa32-4483-bffe-d0a10ab0fb05"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item())) #loss.data[0]\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/8], Step [100/600], Loss: 0.0018\n",
            "Epoch [1/8], Step [200/600], Loss: 0.0049\n",
            "Epoch [1/8], Step [300/600], Loss: 0.0240\n",
            "Epoch [1/8], Step [400/600], Loss: 0.0021\n",
            "Epoch [1/8], Step [500/600], Loss: 0.0300\n",
            "Epoch [1/8], Step [600/600], Loss: 0.0028\n",
            "Epoch [2/8], Step [100/600], Loss: 0.0039\n",
            "Epoch [2/8], Step [200/600], Loss: 0.0041\n",
            "Epoch [2/8], Step [300/600], Loss: 0.0085\n",
            "Epoch [2/8], Step [400/600], Loss: 0.0052\n",
            "Epoch [2/8], Step [500/600], Loss: 0.0077\n",
            "Epoch [2/8], Step [600/600], Loss: 0.0040\n",
            "Epoch [3/8], Step [100/600], Loss: 0.0043\n",
            "Epoch [3/8], Step [200/600], Loss: 0.0062\n",
            "Epoch [3/8], Step [300/600], Loss: 0.0420\n",
            "Epoch [3/8], Step [400/600], Loss: 0.0027\n",
            "Epoch [3/8], Step [500/600], Loss: 0.0057\n",
            "Epoch [3/8], Step [600/600], Loss: 0.0059\n",
            "Epoch [4/8], Step [100/600], Loss: 0.0059\n",
            "Epoch [4/8], Step [200/600], Loss: 0.0042\n",
            "Epoch [4/8], Step [300/600], Loss: 0.0206\n",
            "Epoch [4/8], Step [400/600], Loss: 0.0035\n",
            "Epoch [4/8], Step [500/600], Loss: 0.0006\n",
            "Epoch [4/8], Step [600/600], Loss: 0.0034\n",
            "Epoch [5/8], Step [100/600], Loss: 0.0007\n",
            "Epoch [5/8], Step [200/600], Loss: 0.0009\n",
            "Epoch [5/8], Step [300/600], Loss: 0.0024\n",
            "Epoch [5/8], Step [400/600], Loss: 0.0072\n",
            "Epoch [5/8], Step [500/600], Loss: 0.0035\n",
            "Epoch [5/8], Step [600/600], Loss: 0.0764\n",
            "Epoch [6/8], Step [100/600], Loss: 0.0018\n",
            "Epoch [6/8], Step [200/600], Loss: 0.0006\n",
            "Epoch [6/8], Step [300/600], Loss: 0.0009\n",
            "Epoch [6/8], Step [400/600], Loss: 0.0231\n",
            "Epoch [6/8], Step [500/600], Loss: 0.0062\n",
            "Epoch [6/8], Step [600/600], Loss: 0.0011\n",
            "Epoch [7/8], Step [100/600], Loss: 0.0008\n",
            "Epoch [7/8], Step [200/600], Loss: 0.0024\n",
            "Epoch [7/8], Step [300/600], Loss: 0.0024\n",
            "Epoch [7/8], Step [400/600], Loss: 0.0058\n",
            "Epoch [7/8], Step [500/600], Loss: 0.0013\n",
            "Epoch [7/8], Step [600/600], Loss: 0.0038\n",
            "Epoch [8/8], Step [100/600], Loss: 0.0024\n",
            "Epoch [8/8], Step [200/600], Loss: 0.0010\n",
            "Epoch [8/8], Step [300/600], Loss: 0.0023\n",
            "Epoch [8/8], Step [400/600], Loss: 0.0256\n",
            "Epoch [8/8], Step [500/600], Loss: 0.0080\n",
            "Epoch [8/8], Step [600/600], Loss: 0.0072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhxjhz0tMH0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8dc1517-9979-4c58-e3da-c3ce81f74a0e"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.view(-1, 28*28))\n",
        "    \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "    \n",
        "    \n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "    total += labels.size(0)                    # Increment the total count\n",
        "    correct += (predicted == labels).sum()     # Increment the correct count\n",
        "    \n",
        "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10K test images: 97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcqP-D7sMNHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), 'fnn_model_linwayne.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVsnr0qAQkNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ec59d3b4-694a-4a03-84b0-a4e06ec84e1a"
      },
      "source": [
        "!git clone https://github.com/joosthub/PyTorchNLPBook.git"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorchNLPBook'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Total 159 (delta 0), reused 0 (delta 0), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (159/159), 7.91 MiB | 4.70 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSt-jLOrQmqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cbe1b22b-5c3f-4c81-896d-c94e8b8e6d68"
      },
      "source": [
        "!git clone https://github.com/PacktPublishing/Machine-Learning-for-Finance.git"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Machine-Learning-for-Finance'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 121 (delta 2), reused 0 (delta 0), pack-reused 115\u001b[K\n",
            "Receiving objects: 100% (121/121), 3.78 MiB | 2.96 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}