{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "5_1_Pretrained_Embeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlin988/Colab/blob/master/5_1_Pretrained_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiNY2OzPozEQ",
        "colab_type": "code",
        "outputId": "5d11f1f8-7889-405c-d978-873b91465321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0hI-CEhpToM",
        "colab_type": "code",
        "outputId": "879fd024-4472-4b3e-c4b6-0209e2aeeb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%cd /content/drive/\n",
        "!ls -lta"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "total 8\n",
            "drwx------ 5 root root 4096 Oct 29 17:30 'My Drive'\n",
            "drwx------ 2 root root 4096 Oct 29 17:30  .Trash\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ10rtX9wlOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp -r \"My Drive\"  my_drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtFIVQDjraNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/joosthub/PyTorchNLPBook.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0BliqOdtVbI",
        "colab_type": "code",
        "outputId": "56f6eb08-0ba6-40da-fc67-00cdcb0c2d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pip install annoy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting annoy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/66/eab272ae940d36d698994058e303fe7d1264d10ec120e0a508d0c8fb3ca5/annoy-1.16.2.tar.gz (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.16.2-cp36-cp36m-linux_x86_64.whl size=310421 sha256=0916684f3d8a60f2b1160b5e4a5754d81917cb98d205cb1e598557a000f8aab1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/d7/68/3795670ef4c6781fc10df0d6cf83b922244aa28cd9489d1176\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.16.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08_tfCUks3gC",
        "colab_type": "code",
        "outputId": "b66c3cb8-6ca7-496a-9f33-924f78ffeaaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "%cd /content/drive/My Drive/\n",
        "!ls -lta"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "total 4053\n",
            "drwx------ 2 root root    4096 Oct 27 20:33  folder\n",
            "drwx------ 2 root root    4096 Oct 27 20:28  PyTorchNLPBook\n",
            "drwx------ 2 root root    4096 Oct 26 17:41 'Colab Notebooks'\n",
            "-rw------- 1 root root     151 Oct 25 21:04 'Untitled document (3).gdoc'\n",
            "-rw------- 1 root root     151 Oct 25 09:30 'Untitled document (2).gdoc'\n",
            "-rw------- 1 root root 1453568 Sep 16  2014 '2A-4 -  6WINDGate Multi-Core Networking SW - Level 2 v5.4.ppt'\n",
            "-rw------- 1 root root   56383 Jun 27  2014 '5th Spelling W & Def 91-100 (3).pdf'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document (1).gdoc'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document.gdoc'\n",
            "-rw------- 1 root root  269382 Mar 17  2014 'Print from a Chromebook with Google Cloud Print - YouTube.pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014  Google.pdf\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (1).pdf'\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (2).pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014 'Google (3).pdf'\n",
            "-rw------- 1 root root   74283 Mar 17  2014 'New Tab.pdf'\n",
            "-rw------- 1 root root   63315 Mar 17  2014  williamdropbox.pdf\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (4).pdf'\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (5).pdf'\n",
            "-rw------- 1 root root  963715 Mar 17  2014 'Cloud Print test page.pdf'\n",
            "-rw------- 1 root root     151 Mar  9  2014 'Untitled document (5).gdoc'\n",
            "-rw------- 1 root root     151 Mar  3  2014 'Untitled document (4).gdoc'\n",
            "-rw------- 1 root root   33061 Feb  5  2014  13915594519295830.gif\n",
            "-rw------- 1 root root   87040 Jan 14  2012  SCSI_vs_FC.pdf\n",
            "-rw------- 1 root root  754006 Jan 14  2012  White_Paper_Fibre_Channel_Fundamentals.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v9fceE-tiWP",
        "colab_type": "code",
        "outputId": "21f29fed-2468-453e-d3a3-c88d8dbfb3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "%cd data\n",
        "!ls -lta"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'data'\n",
            "/content/drive/My Drive\n",
            "total 4053\n",
            "drwx------ 2 root root    4096 Oct 27 20:33  folder\n",
            "drwx------ 2 root root    4096 Oct 27 20:28  PyTorchNLPBook\n",
            "drwx------ 2 root root    4096 Oct 26 17:41 'Colab Notebooks'\n",
            "-rw------- 1 root root     151 Oct 25 21:04 'Untitled document (3).gdoc'\n",
            "-rw------- 1 root root     151 Oct 25 09:30 'Untitled document (2).gdoc'\n",
            "-rw------- 1 root root 1453568 Sep 16  2014 '2A-4 -  6WINDGate Multi-Core Networking SW - Level 2 v5.4.ppt'\n",
            "-rw------- 1 root root   56383 Jun 27  2014 '5th Spelling W & Def 91-100 (3).pdf'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document (1).gdoc'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document.gdoc'\n",
            "-rw------- 1 root root  269382 Mar 17  2014 'Print from a Chromebook with Google Cloud Print - YouTube.pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014  Google.pdf\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (1).pdf'\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (2).pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014 'Google (3).pdf'\n",
            "-rw------- 1 root root   74283 Mar 17  2014 'New Tab.pdf'\n",
            "-rw------- 1 root root   63315 Mar 17  2014  williamdropbox.pdf\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (4).pdf'\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (5).pdf'\n",
            "-rw------- 1 root root  963715 Mar 17  2014 'Cloud Print test page.pdf'\n",
            "-rw------- 1 root root     151 Mar  9  2014 'Untitled document (5).gdoc'\n",
            "-rw------- 1 root root     151 Mar  3  2014 'Untitled document (4).gdoc'\n",
            "-rw------- 1 root root   33061 Feb  5  2014  13915594519295830.gif\n",
            "-rw------- 1 root root   87040 Jan 14  2012  SCSI_vs_FC.pdf\n",
            "-rw------- 1 root root  754006 Jan 14  2012  White_Paper_Fibre_Channel_Fundamentals.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnBSx25nvbu9",
        "colab_type": "code",
        "outputId": "4b4e947a-5522-46c2-bd48-84278e6a4966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/\"My Drive\"/PyTorchNLPBook/chapters/chapter_5/data\n",
        "!pwd\n",
        "!ls -lta"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data\n",
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data\n",
            "total 52\n",
            "drwx------ 2 root root  4096 Oct 28 18:59 .ipynb_checkpoints\n",
            "-rw------- 1 root root  1961 Oct 28 17:58 get-all-data.sh\n",
            "-rw------- 1 root root  1572 Oct 27 20:28 download.py\n",
            "-rw------- 1 root root  6148 Oct 27 20:28 .DS_Store\n",
            "-rw------- 1 root root   572 Oct 27 20:28 README.md\n",
            "-rw------- 1 root root 12288 Oct 27 20:28 .README.md.swp\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 ag_news\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 books\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 glove\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 nmt\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 surnames\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lt-KVEjvm_t",
        "colab_type": "code",
        "outputId": "1b453b6f-6df8-44a4-e32c-9d3c16f00c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 52\n",
            "drwx------ 2 root root  4096 Oct 28 18:59 .ipynb_checkpoints\n",
            "-rwx------ 1 root root  1961 Oct 28 17:58 get-all-data.sh\n",
            "-rw------- 1 root root  1572 Oct 27 20:28 download.py\n",
            "-rw------- 1 root root  6148 Oct 27 20:28 .DS_Store\n",
            "-rw------- 1 root root   572 Oct 27 20:28 README.md\n",
            "-rw------- 1 root root 12288 Oct 27 20:28 .README.md.swp\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 ag_news\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 books\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 glove\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 nmt\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 surnames\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzhVjupYtorh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk726G-AybIR",
        "colab_type": "code",
        "outputId": "a3b9e8b9-5764-4013-bcda-002a2b60e20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!mkdir -p glove\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data\n",
            "ag_news  download.py\t  glove  README.md  yelp\n",
            "books\t get-all-data.sh  nmt\t surnames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RckCHAIOyiU1",
        "colab_type": "code",
        "outputId": "038b0457-ebcd-4366-d380-e5a61e528f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/drive/\"My Drive\"/PyTorchNLPBook/chapters/chapter_5/data/glove\n",
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data/glove\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxegpf2ys9U",
        "colab_type": "code",
        "outputId": "ccdaea45-33df-4880-f4e6-a64b5b9b94f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘glove.6B.zip’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNZKb5KizEqH",
        "colab_type": "code",
        "outputId": "e22d9018-a73a-4385-e752-5d36afdf06cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls\n",
        "!unzip -n glove.6B.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt\n",
            "Archive:  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW2FzFT81hb7",
        "colab_type": "code",
        "outputId": "1e565aaa-8a6d-4719-de43-bc40b1dc31d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pwd\n",
        "%cd ../..\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data/glove\n",
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5\n",
            "5_1_Pretrained_Embeddings.ipynb  5_3_doc_classification  model_storage\n",
            "5_2_CBOW\t\t\t data\t\t\t README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-6w8wxsLsS",
        "colab_type": "code",
        "outputId": "3cc24332-cdf9-4c05-b56a-9d18cb231d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "%run 5_1_Pretrained_Embeddings.ipynb"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Index!\n",
            "Finished!\n",
            "man : he :: woman : she\n",
            "man : he :: woman : never\n",
            "fly : plane :: sail : ship\n",
            "fly : plane :: sail : vessel\n",
            "cat : kitten :: dog : puppy\n",
            "cat : kitten :: dog : toddler\n",
            "cat : kitten :: dog : sleds\n",
            "blue : color :: dog : cat\n",
            "blue : color :: dog : animal\n",
            "blue : color :: dog : breed\n",
            "leg : legs :: hand : fingers\n",
            "leg : legs :: hand : ears\n",
            "leg : legs :: hand : stick\n",
            "toe : foot :: finger : hand\n",
            "toe : foot :: finger : attached\n",
            "toe : foot :: finger : apart\n",
            "talk : communicate :: read : instructions\n",
            "talk : communicate :: read : communicating\n",
            "talk : communicate :: read : transmit\n",
            "blue : democrat :: red : republican\n",
            "blue : democrat :: red : congressman\n",
            "blue : democrat :: red : senator\n",
            "man : king :: woman : queen\n",
            "man : king :: woman : monarch\n",
            "man : king :: woman : throne\n",
            "man : doctor :: woman : nurse\n",
            "man : doctor :: woman : physician\n",
            "fast : fastest :: small : smallest\n",
            "fast : fastest :: small : largest\n",
            "fast : fastest :: small : among\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW4YXw_HpfkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os\n",
        "#from getpass import getpass\n",
        "#import urllib\n",
        "\n",
        "#cmd = 'git clone https://github.com/joosthub/PyTorchNLPBook.git'\n",
        "#os.system(cmd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWaXMihaoiaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3lhylHKoiaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreTrainedEmbeddings(object):\n",
        "    \"\"\" A wrapper around pre-trained word vectors and their use \"\"\"\n",
        "    def __init__(self, word_to_index, word_vectors):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word_to_index (dict): mapping from word to integers\n",
        "            word_vectors (list of numpy arrays)\n",
        "        \"\"\"\n",
        "        self.word_to_index = word_to_index\n",
        "        self.word_vectors = word_vectors%run 5_2_Continuous_Bag_of_Words_CBOE.ipynb\n",
        "        self.index_to_word = {v: k for k, v in self.word_to_index.items()}\n",
        "\n",
        "        self.index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\n",
        "        print(\"Building Index!\")\n",
        "        for _, i in self.word_to_index.items():\n",
        "            self.index.add_item(i, self.word_vectors[i])\n",
        "        self.index.build(50)\n",
        "        print(\"Finished!\")\n",
        "        \n",
        "    @classmethod\n",
        "    def from_embeddings_file(cls, embedding_file):\n",
        "        \"\"\"Instantiate from pre-trained vector file.\n",
        "        \n",
        "        Vector file should be of the format:\n",
        "            word0 x0_0 x0_1 x0_2 x0_3 ... x0_N\n",
        "            word1 x1_0 x1_1 x1_2 x1_3 ... x1_N\n",
        "        \n",
        "        Args:\n",
        "            embedding_file (str): location of the file\n",
        "        Returns: \n",
        "            instance of PretrainedEmbeddigns\n",
        "        \"\"\"\n",
        "        word_to_index = {}\n",
        "        word_vectors = []\n",
        "\n",
        "        with open(embedding_file) as fp:\n",
        "            for line in fp.readlines():\n",
        "                line = line.split(\" \")\n",
        "                word = line[0]\n",
        "                vec = np.array([float(x) for x in line[1:]])\n",
        "                \n",
        "                word_to_index[word] = len(word_to_index)\n",
        "                word_vectors.append(vec)\n",
        "                \n",
        "        return cls(word_to_index, word_vectors)\n",
        "    \n",
        "    def get_embedding(self, word):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word (str)\n",
        "        Returns\n",
        "            an embedding (numpy.ndarray)\n",
        "        \"\"\"\n",
        "        return self.word_vectors[self.word_to_index[word]]\n",
        "\n",
        "    def get_closest_to_vector(self, vector, n=1):\n",
        "        \"\"\"Given a vector, return its n nearest neighbors\n",
        "        \n",
        "        Args:\n",
        "            vector (np.ndarray): should match the size of the vectors \n",
        "                in the Annoy index\n",
        "            n (int): the number of neighbors to return\n",
        "        Returns:\n",
        "            [str, str, ...]: words that are nearest to the given vector. \n",
        "                The words are not ordered by distance \n",
        "        \"\"\"\n",
        "        nn_indices = self.index.get_nns_by_vector(vector, n)\n",
        "        return [self.index_to_word[neighbor] for neighbor in nn_indices]\n",
        "    \n",
        "    def compute_and_print_analogy(self, word1, word2, word3):\n",
        "        \"\"\"Prints the solutions to analogies using word embeddings\n",
        "\n",
        "        Analogies are word1 is to word2 as word3 is to __\n",
        "        This method will print: word1 : word2 :: word3 : word4\n",
        "        \n",
        "        Args:\n",
        "            word1 (str)\n",
        "            word2 (str)\n",
        "            word3 (str)\n",
        "        \"\"\"\n",
        "        vec1 = self.get_embedding(word1)\n",
        "        vec2 = self.get_embedding(word2)\n",
        "        vec3 = self.get_embedding(word3)\n",
        "\n",
        "        # now compute the fourth word's embedding!\n",
        "        spatial_relationship = vec2 - vec1\n",
        "        vec4 = vec3 + spatial_relationship\n",
        "\n",
        "        closest_words = self.get_closest_to_vector(vec4, n=4)\n",
        "        existing_words = set([word1, word2, word3])\n",
        "        closest_words = [word for word in closest_words \n",
        "                             if word not in existing_words] \n",
        "\n",
        "        if len(closest_words) == 0:\n",
        "            print(\"Could not find nearest neighbors for the computed vector!\")\n",
        "            return\n",
        "        \n",
        "        for word4 in closest_words:\n",
        "            print(\"{} : {} :: {} : {}\".format(word1, word2, word3, word4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocmiqct3oiaJ",
        "colab_type": "code",
        "outputId": "92862483-aeb3-4ee3-b915-6649a4f6b300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings = PreTrainedEmbeddings.from_embeddings_file('data/glove/glove.6B.100d.txt')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Index!\n",
            "Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3wGNNEZoiaM",
        "colab_type": "code",
        "outputId": "0d5348fc-5256-4872-effb-b99040af31bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('man', 'he', 'woman')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man : he :: woman : she\n",
            "man : he :: woman : never\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNx1jB-oiaO",
        "colab_type": "code",
        "outputId": "af262c3b-ecb8-4dbc-9c37-030905c5bc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('fly', 'plane', 'sail')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fly : plane :: sail : ship\n",
            "fly : plane :: sail : vessel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgnrbKDoiaQ",
        "colab_type": "code",
        "outputId": "e42945c3-85b8-4756-8e5e-d747822e3b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('cat', 'kitten', 'dog')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat : kitten :: dog : puppy\n",
            "cat : kitten :: dog : toddler\n",
            "cat : kitten :: dog : sleds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55oog0dVoiaS",
        "colab_type": "code",
        "outputId": "3e4d5d03-d8c2-4a62-f3d9-d07d02c3f80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('blue', 'color', 'dog')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blue : color :: dog : cat\n",
            "blue : color :: dog : animal\n",
            "blue : color :: dog : breed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXwa7Jr6oiaU",
        "colab_type": "code",
        "outputId": "51adcd0a-01c3-4d00-833c-a6042c6c9819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('leg', 'legs', 'hand')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "leg : legs :: hand : fingers\n",
            "leg : legs :: hand : ears\n",
            "leg : legs :: hand : stick\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6SOG1ZboiaW",
        "colab_type": "code",
        "outputId": "4db7c119-82c1-4df5-aa81-92428af3213e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('toe', 'foot', 'finger')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toe : foot :: finger : hand\n",
            "toe : foot :: finger : attached\n",
            "toe : foot :: finger : apart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxRm5AYMoiaY",
        "colab_type": "code",
        "outputId": "9d6f107a-d52a-4eaa-9cc9-75e224d85d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('talk', 'communicate', 'read')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "talk : communicate :: read : instructions\n",
            "talk : communicate :: read : communicating\n",
            "talk : communicate :: read : transmit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXC90XtKoiaa",
        "colab_type": "code",
        "outputId": "1e2cedff-27b7-47d7-a332-69b0fb4c8aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('blue', 'democrat', 'red')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blue : democrat :: red : republican\n",
            "blue : democrat :: red : congressman\n",
            "blue : democrat :: red : senator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d4G05Xoiac",
        "colab_type": "code",
        "outputId": "e15ea24d-1ea8-43b6-8483-c95c39445667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('man', 'king', 'woman')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man : king :: woman : queen\n",
            "man : king :: woman : monarch\n",
            "man : king :: woman : throne\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEVpskfroiae",
        "colab_type": "code",
        "outputId": "eeb6559b-19bf-4bd7-9693-7fd6bf000564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('man', 'doctor', 'woman')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man : doctor :: woman : nurse\n",
            "man : doctor :: woman : physician\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiczV7Ixoiag",
        "colab_type": "code",
        "outputId": "010003c2-827f-4766-fe66-78ccece0626b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('fast', 'fastest', 'small')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fast : fastest :: small : smallest\n",
            "fast : fastest :: small : largest\n",
            "fast : fastest :: small : among\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9huX8YynvOaX",
        "colab_type": "code",
        "outputId": "da7a7049-70f8-42f2-eeda-3dd5a4d69db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW/data\n",
        "!ls\n",
        "!chmod 777 get-all-data.sh\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW/data\n",
            "ag_news  download.py\t  glove  README.md  yelp\n",
            "books\t get-all-data.sh  nmt\t surnames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pop56TTbd-NA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b328e1e-5539-48c1-c4b0-319a198bbdc3"
      },
      "source": [
        "!mkdir -p glove\n",
        "%cd glove\n",
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -n glove.6B.zip"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW/data/glove\n",
            "File ‘glove.6B.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryeRe_ISd963",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "faa1fa4c-7972-449d-9756-a83fb641eab8"
      },
      "source": [
        "%cd /content/drive/\"My Drive\"/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW\n",
        "!ls"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW\n",
            "5_2_Continuous_Bag_of_Words_CBOW.ipynb\tdata\n",
            "5_2_munging_frankenstein.ipynb\t\tmodel_storage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XHSNhPkfeqe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d06a7199-188b-4a8b-91ec-9622e10bd54f"
      },
      "source": [
        "%run 5_2_Continuous_Bag_of_Words_CBOW.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tmodel_storage/ch5/cbow/vectorizer.json\n",
            "\tmodel_storage/ch5/cbow/model.pth\n",
            "Using CUDA: True\n",
            "Loading dataset and creating vectorizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf7306a887b94e4daf5d15f8ecd3c300",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='training routine', style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8081d7edf7749d1b59908f63d192614",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='split=train', max=1984, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed8cbdc4f3cc4f20a1ae272825e95d1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='split=val', max=425, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfw0EGcEd9rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run 5_2_munging_frankenstein.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9JYGN7Fh2PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_3_doc_classification/data\n",
        "!ls\n",
        "!chmod 777 get-all-data.sh\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR60DUEpwBlO",
        "colab_type": "code",
        "outputId": "97a561f2-f596-4b75-c789-004aa56ddb7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/data"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL0OJxG_tmS8",
        "colab_type": "code",
        "outputId": "23cae38c-2ae8-49c4-e745-7a7d4ce4c0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 26\n",
            "-rwx------ 1 root root 1961 Oct 28 17:57 get-all-data.sh\n",
            "-rw------- 1 root root 1929 Oct 27 20:28 README.md\n",
            "-rw------- 1 root root 1572 Oct 27 20:28 download.py\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 surnames\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 ag_news\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 books\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 nmt\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiq9rd1yugb2",
        "colab_type": "code",
        "outputId": "eaf3590f-a489-48d2-9f00-6544e20cc7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_1\n",
        "!ls"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_1\n",
            "PyTorch_Basics.ipynb  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfFVLzzL08gp",
        "colab_type": "code",
        "outputId": "c82dc0c2-ee06-47bb-edb4-13ccb0428fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%run PyTorch_Basics.ipynb"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[9.1040e-36, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 9.3887e-44]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.0461,  0.4024, -1.0115],\n",
            "        [ 0.2167, -0.6123,  0.5036]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.7749, 0.8208, 0.2793],\n",
            "        [0.6817, 0.2837, 0.6567]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.]])\n",
            "torch.FloatTensor\n",
            "torch.Size([3, 4])\n",
            "tensor([[5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [2., 4.]])\n",
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.4172, 0.5313, 0.7668],\n",
            "        [0.7396, 0.2781, 0.6444]], dtype=torch.float64)\n",
            "float64\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 1.5385, -0.9757,  1.5769],\n",
            "        [ 0.3840, -0.6039, -0.5240]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 3.0771, -1.9515,  3.1539],\n",
            "        [ 0.7680, -1.2077, -1.0479]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 3.0771, -1.9515,  3.1539],\n",
            "        [ 0.7680, -1.2077, -1.0479]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([6])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([3, 5, 7])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([ 3, 12])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 2])\n",
            "Values: \n",
            "tensor([[0, 1]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "1\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[0, 2],\n",
            "        [3, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [0, 1, 2]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0, 4])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "torch.int64\n",
            "int64\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19]])\n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19]])\n",
            "tensor([[ 0],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [ 6],\n",
            "        [ 7],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [11],\n",
            "        [12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[0, 1, 2, 3]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 4,  6,  8, 10],\n",
            "        [ 8, 10, 12, 14]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [10, 11, 12, 13]])\n",
            "torch.Size([3, 4])\n",
            "torch.Size([3, 1, 4])\n",
            "torch.Size([3, 4])\n",
            "x: \n",
            " tensor([[0.6662, 0.3343, 0.7893, 0.3216],\n",
            "        [0.5247, 0.6688, 0.8436, 0.4265],\n",
            "        [0.9561, 0.0770, 0.4108, 0.0014]])\n",
            "--\n",
            "torch.add(x, x): \n",
            " tensor([[1.3324, 0.6686, 1.5786, 0.6433],\n",
            "        [1.0494, 1.3377, 1.6872, 0.8530],\n",
            "        [1.9123, 0.1540, 0.8216, 0.0028]])\n",
            "--\n",
            "x+x: \n",
            " tensor([[1.3324, 0.6686, 1.5786, 0.6433],\n",
            "        [1.0494, 1.3377, 1.6872, 0.8530],\n",
            "        [1.9123, 0.1540, 0.8216, 0.0028]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 8, 10, 12, 14],\n",
            "        [16, 18, 20, 22]])\n",
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "Summing across rows (dim=0): \n",
            " tensor([12, 15, 18, 21])\n",
            "---\n",
            "Summing across columns (dim=1): \n",
            " tensor([ 6, 22, 38])\n",
            "x: \n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "---\n",
            "x[:2, :2]: \n",
            " tensor([[0, 1],\n",
            "        [3, 4]])\n",
            "---\n",
            "x[0][1]: \n",
            " tensor(1)\n",
            "---\n",
            "Setting [0][1] to be 8\n",
            "tensor([[0, 8, 2],\n",
            "        [3, 4, 5]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 9])\n",
            "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
            "        [6, 7, 8, 6, 7, 8, 6, 7, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 3, 3])\n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]])\n",
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "x.tranpose(1, 0): \n",
            " tensor([[ 0,  4,  8],\n",
            "        [ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11]])\n",
            "x.shape: \n",
            " torch.Size([3, 4, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "-----\n",
            "x.transpose(1, 0).shape: \n",
            " torch.Size([4, 3, 5])\n",
            "x.transpose(1, 0): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [20, 21, 22, 23, 24],\n",
            "         [40, 41, 42, 43, 44]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [45, 46, 47, 48, 49]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [50, 51, 52, 53, 54]],\n",
            "\n",
            "        [[15, 16, 17, 18, 19],\n",
            "         [35, 36, 37, 38, 39],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "x.shape: \n",
            " torch.Size([3, 4, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "-----\n",
            "x.permute(1, 0, 2).shape: \n",
            " torch.Size([4, 3, 5])\n",
            "x.permute(1, 0, 2): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [20, 21, 22, 23, 24],\n",
            "         [40, 41, 42, 43, 44]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [45, 46, 47, 48, 49]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [50, 51, 52, 53, 54]],\n",
            "\n",
            "        [[15, 16, 17, 18, 19],\n",
            "         [35, 36, 37, 38, 39],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[ 3.,  6.],\n",
            "        [12., 24.]])\n",
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]])\n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n",
            "tensor([[ 6., 12.],\n",
            "        [22., 44.],\n",
            "        [38., 76.]])\n",
            "tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
            "x: \n",
            " tensor([[2., 3.]], requires_grad=True)\n",
            "---\n",
            "z = 3*x: \n",
            " tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
            "---\n",
            "loss = z.sum(): \n",
            " tensor(15., grad_fn=<SumBackward0>)\n",
            "---\n",
            "after loss.backward(), x.grad: \n",
            " tensor([[3., 3.]])\n",
            "tensor([0.5403])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_1/PyTorch_Basics.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# this is meant to break!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ql_yub1d5V",
        "colab_type": "code",
        "outputId": "52f081bb-331d-4357-dd7f-30479b712e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_3/data\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_3/data\n",
            "ag_news  download.py  get-all-data.sh  README.md  yelp\n",
            "books\t Drive\t      nmt\t       surnames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioRyRp7J1zTI",
        "colab_type": "code",
        "outputId": "34c2c298-75c5-420d-c4da-bbea4a44909a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 29\n",
            "drwx------ 2 root root 4096 Oct 29 04:49 nmt\n",
            "drwx------ 2 root root 4096 Oct 29 04:49 ag_news\n",
            "drwx------ 2 root root 4096 Oct 29 04:49 books\n",
            "drwx------ 2 root root 4096 Oct 29 04:49 surnames\n",
            "-rwx------ 1 root root 1961 Oct 29 04:48 get-all-data.sh\n",
            "drwx------ 2 root root 4096 Oct 29 04:48 yelp\n",
            "drwx------ 2 root root 4096 Oct 29 04:47 Drive\n",
            "-rw------- 1 root root 1572 Oct 27 20:28 download.py\n",
            "-rw------- 1 root root  572 Oct 27 20:28 README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd0qmgWr2aFL",
        "colab_type": "code",
        "outputId": "81c1e95d-88b6-4b29-f3cf-48a728631958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%cd ..\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_3\n",
            "3_5_Classifying_Yelp_Review_Sentiment.ipynb\t      data\n",
            "3_5_yelp_dataset_preprocessing_FULL.ipynb\t      model_storage\n",
            "3_5_yelp_dataset_preprocessing_LITE.ipynb\t      perceptron_final.pdf\n",
            "Chapter-3-Diving-Deep-into-Supervised-Training.ipynb  perceptron_final.png\n",
            "Chapter-3-In-Text-Examples.ipynb\t\t      README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fA0Ujk-3L9L",
        "colab_type": "code",
        "outputId": "63e5aadd-7471-4ad8-db3a-a7f5403029b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%run 3_5_Classifying_Yelp_Review_Sentiment.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expanded filepaths: \n",
            "\tmodel_storage/ch3/yelp/vectorizer.json\n",
            "\tmodel_storage/ch3/yelp/model.pth\n",
            "Using CUDA: True\n",
            "Loading dataset and creating vectorizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c60116cdaa654ea0b899d28dad9d0254",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='training routine', style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86e5b14559be420695831a05e206dd8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='split=train', max=306, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76101d04a6cd4cdeb9da1fddb8d5a788",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='split=val', max=65, style=ProgressStyle(description_width='in…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK62wU0t3SHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run 3_5_yelp_dataset_preprocessing_FULL.ipynb4/sgGsK2WYoymZo2ADfM_fCcUMgSWZuQHeWTAlK9uppqg6fzbsmuezF4I"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeepD3IlfcQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run 3_5_yelp_dataset_preprocessing_LITE.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfaDw95bfjp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run Chapter-3-Diving-Deep-into-Supervised-Training.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPJvX8l6fzW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run Chapter-3-In-Text-Examples.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HudRBNSMgW8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqgAB9oxpPgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1dFJQk5npRSs",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_6/classifying-surnames/data\n",
        "!ls\n",
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn9men6ipzv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!ls\n",
        "%run Chapter-6-Munging-Surname-Dataset.ipynb\n",
        "%run Chapter-6-Surname-Classification-with-RNNs.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_BBdM5dqSyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_7/7_3_surname_generation/data\n",
        "!ls\n",
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu3ceQtvqfmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!ls\n",
        "%run 7_3_Model1_Unconditioned_Surname_Generation.ipynb\n",
        "%run 7_3_Model2_Conditioned_Surname_Generation.ipynb\n",
        "%run Munging_Surname_Dataset.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHlt2O8qfcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_8/8_5_NMT/data\n",
        "!ls\n",
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSUmqpwYrHrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!ls\n",
        "%run 8_5_NMT_No_Sampling.ipynb\n",
        "%run 8_5_NMT_scheduled_sampling.ipynb\n",
        "%run 8_5_nmt_munging.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}