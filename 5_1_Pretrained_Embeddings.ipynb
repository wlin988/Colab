{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "5_1_Pretrained_Embeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlin988/Colab/blob/master/5_1_Pretrained_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiNY2OzPozEQ",
        "colab_type": "code",
        "outputId": "51e8832c-35e6-4b8c-b167-699c4bbbe4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0hI-CEhpToM",
        "colab_type": "code",
        "outputId": "d13d1528-5943-4bdd-93c9-f224af73d0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%cd /content/drive/\n",
        "!ls -lta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "total 8\n",
            "drwx------ 5 root root 4096 Oct 29 04:19 'My Drive'\n",
            "drwx------ 2 root root 4096 Oct 29 04:19  .Trash\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ10rtX9wlOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp -r \"My Drive\"  my_drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtFIVQDjraNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/joosthub/PyTorchNLPBook.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0BliqOdtVbI",
        "colab_type": "code",
        "outputId": "accfc134-fa94-4a64-9005-24a3fa1a9831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pip install annoy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting annoy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/66/eab272ae940d36d698994058e303fe7d1264d10ec120e0a508d0c8fb3ca5/annoy-1.16.2.tar.gz (636kB)\n",
            "\r\u001b[K     |▌                               | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 3.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.16.2-cp36-cp36m-linux_x86_64.whl size=310432 sha256=55774b8c6840fc1f44dbc611963d22f5bf21c5b9dfc1389995abbe9548223e30\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/d7/68/3795670ef4c6781fc10df0d6cf83b922244aa28cd9489d1176\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.16.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08_tfCUks3gC",
        "colab_type": "code",
        "outputId": "764636eb-18dc-461f-ec27-536f01104d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "%cd /content/drive/My Drive/\n",
        "!ls -lta"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "total 4053\n",
            "drwx------ 2 root root    4096 Oct 27 20:33  folder\n",
            "drwx------ 2 root root    4096 Oct 27 20:28  PyTorchNLPBook\n",
            "drwx------ 2 root root    4096 Oct 26 17:41 'Colab Notebooks'\n",
            "-rw------- 1 root root     151 Oct 25 21:04 'Untitled document (3).gdoc'\n",
            "-rw------- 1 root root     151 Oct 25 09:30 'Untitled document (2).gdoc'\n",
            "-rw------- 1 root root 1453568 Sep 16  2014 '2A-4 -  6WINDGate Multi-Core Networking SW - Level 2 v5.4.ppt'\n",
            "-rw------- 1 root root   56383 Jun 27  2014 '5th Spelling W & Def 91-100 (3).pdf'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document (1).gdoc'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document.gdoc'\n",
            "-rw------- 1 root root  269382 Mar 17  2014 'Print from a Chromebook with Google Cloud Print - YouTube.pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014  Google.pdf\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (1).pdf'\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (2).pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014 'Google (3).pdf'\n",
            "-rw------- 1 root root   74283 Mar 17  2014 'New Tab.pdf'\n",
            "-rw------- 1 root root   63315 Mar 17  2014  williamdropbox.pdf\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (4).pdf'\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (5).pdf'\n",
            "-rw------- 1 root root  963715 Mar 17  2014 'Cloud Print test page.pdf'\n",
            "-rw------- 1 root root     151 Mar  9  2014 'Untitled document (5).gdoc'\n",
            "-rw------- 1 root root     151 Mar  3  2014 'Untitled document (4).gdoc'\n",
            "-rw------- 1 root root   33061 Feb  5  2014  13915594519295830.gif\n",
            "-rw------- 1 root root   87040 Jan 14  2012  SCSI_vs_FC.pdf\n",
            "-rw------- 1 root root  754006 Jan 14  2012  White_Paper_Fibre_Channel_Fundamentals.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v9fceE-tiWP",
        "colab_type": "code",
        "outputId": "54f581e9-fe78-4bd1-da8a-e76ee5ba50d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "%cd data\n",
        "!ls -lta"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'data'\n",
            "/content/drive/My Drive\n",
            "total 4053\n",
            "drwx------ 2 root root    4096 Oct 27 20:33  folder\n",
            "drwx------ 2 root root    4096 Oct 27 20:28  PyTorchNLPBook\n",
            "drwx------ 2 root root    4096 Oct 26 17:41 'Colab Notebooks'\n",
            "-rw------- 1 root root     151 Oct 25 21:04 'Untitled document (3).gdoc'\n",
            "-rw------- 1 root root     151 Oct 25 09:30 'Untitled document (2).gdoc'\n",
            "-rw------- 1 root root 1453568 Sep 16  2014 '2A-4 -  6WINDGate Multi-Core Networking SW - Level 2 v5.4.ppt'\n",
            "-rw------- 1 root root   56383 Jun 27  2014 '5th Spelling W & Def 91-100 (3).pdf'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document (1).gdoc'\n",
            "-rw------- 1 root root     151 Apr 30  2014 'Untitled document.gdoc'\n",
            "-rw------- 1 root root  269382 Mar 17  2014 'Print from a Chromebook with Google Cloud Print - YouTube.pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014  Google.pdf\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (1).pdf'\n",
            "-rw------- 1 root root   56471 Mar 17  2014 'Google (2).pdf'\n",
            "-rw------- 1 root root   69344 Mar 17  2014 'Google (3).pdf'\n",
            "-rw------- 1 root root   74283 Mar 17  2014 'New Tab.pdf'\n",
            "-rw------- 1 root root   63315 Mar 17  2014  williamdropbox.pdf\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (4).pdf'\n",
            "-rw------- 1 root root   62091 Mar 17  2014 'Google (5).pdf'\n",
            "-rw------- 1 root root  963715 Mar 17  2014 'Cloud Print test page.pdf'\n",
            "-rw------- 1 root root     151 Mar  9  2014 'Untitled document (5).gdoc'\n",
            "-rw------- 1 root root     151 Mar  3  2014 'Untitled document (4).gdoc'\n",
            "-rw------- 1 root root   33061 Feb  5  2014  13915594519295830.gif\n",
            "-rw------- 1 root root   87040 Jan 14  2012  SCSI_vs_FC.pdf\n",
            "-rw------- 1 root root  754006 Jan 14  2012  White_Paper_Fibre_Channel_Fundamentals.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnBSx25nvbu9",
        "colab_type": "code",
        "outputId": "b1ccba6d-c3fb-424e-ab70-18757b291f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "\n",
        "%cd /content/drive/\"My Drive\"/PyTorchNLPBook/chapters/chapter_5/data\n",
        "!pwd\n",
        "!ls -lta"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data\n",
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data\n",
            "total 52\n",
            "drwx------ 2 root root  4096 Oct 28 18:59 .ipynb_checkpoints\n",
            "-rw------- 1 root root  1961 Oct 28 17:58 get-all-data.sh\n",
            "-rw------- 1 root root  1572 Oct 27 20:28 download.py\n",
            "-rw------- 1 root root  6148 Oct 27 20:28 .DS_Store\n",
            "-rw------- 1 root root   572 Oct 27 20:28 README.md\n",
            "-rw------- 1 root root 12288 Oct 27 20:28 .README.md.swp\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 ag_news\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 books\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 glove\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 nmt\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 surnames\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lt-KVEjvm_t",
        "colab_type": "code",
        "outputId": "fbd8014c-cf60-4f1c-c635-fc4884cba7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 52\n",
            "drwx------ 2 root root  4096 Oct 28 18:59 .ipynb_checkpoints\n",
            "-rwx------ 1 root root  1961 Oct 28 17:58 get-all-data.sh\n",
            "-rw------- 1 root root  1572 Oct 27 20:28 download.py\n",
            "-rw------- 1 root root  6148 Oct 27 20:28 .DS_Store\n",
            "-rw------- 1 root root   572 Oct 27 20:28 README.md\n",
            "-rw------- 1 root root 12288 Oct 27 20:28 .README.md.swp\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 ag_news\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 books\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 glove\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 nmt\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 surnames\n",
            "drwx------ 2 root root  4096 Oct 27 20:28 yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzhVjupYtorh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ./get-all-data.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk726G-AybIR",
        "colab_type": "code",
        "outputId": "0bde539d-d18c-4486-ff6f-eb884b17ccb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!mkdir -p glove\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data\n",
            "ag_news  download.py\t  glove  README.md  yelp\n",
            "books\t get-all-data.sh  nmt\t surnames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RckCHAIOyiU1",
        "colab_type": "code",
        "outputId": "5e9ad147-8ece-45a3-ae7f-03d8c59a2ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd /content/drive/\"My Drive\"/PyTorchNLPBook/chapters/chapter_5/data/glove\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data/glove\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxegpf2ys9U",
        "colab_type": "code",
        "outputId": "1425a1d0-1d06-4033-8728-a891f69ac5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘glove.6B.zip’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNZKb5KizEqH",
        "colab_type": "code",
        "outputId": "98575ecd-f956-43c3-9e3a-81fc61f5a285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls\n",
        "!unzip -n glove.6B.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt\n",
            "Archive:  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW2FzFT81hb7",
        "colab_type": "code",
        "outputId": "cab0c0c7-cd3b-4eac-c66d-f7824160777c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pwd\n",
        "%cd ../..\n",
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/data/glove\n",
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5\n",
            "5_1_Pretrained_Embeddings.ipynb  5_3_doc_classification  model_storage\n",
            "5_2_CBOW\t\t\t data\t\t\t README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-6w8wxsLsS",
        "colab_type": "code",
        "outputId": "05f0a303-2961-477d-926d-b15492a950b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "%run 5_1_Pretrained_Embeddings.ipynb"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Index!\n",
            "Finished!\n",
            "man : he :: woman : she\n",
            "man : he :: woman : never\n",
            "fly : plane :: sail : ship\n",
            "fly : plane :: sail : vessel\n",
            "cat : kitten :: dog : puppy\n",
            "cat : kitten :: dog : toddler\n",
            "cat : kitten :: dog : sleds\n",
            "blue : color :: dog : cat\n",
            "blue : color :: dog : animal\n",
            "blue : color :: dog : breed\n",
            "leg : legs :: hand : fingers\n",
            "leg : legs :: hand : ears\n",
            "leg : legs :: hand : stick\n",
            "toe : foot :: finger : hand\n",
            "toe : foot :: finger : attached\n",
            "toe : foot :: finger : apart\n",
            "talk : communicate :: read : instructions\n",
            "talk : communicate :: read : communicating\n",
            "talk : communicate :: read : transmit\n",
            "blue : democrat :: red : republican\n",
            "blue : democrat :: red : congressman\n",
            "blue : democrat :: red : senator\n",
            "man : king :: woman : queen\n",
            "man : king :: woman : monarch\n",
            "man : king :: woman : throne\n",
            "man : doctor :: woman : nurse\n",
            "man : doctor :: woman : physician\n",
            "fast : fastest :: small : smallest\n",
            "fast : fastest :: small : largest\n",
            "fast : fastest :: small : among\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW4YXw_HpfkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os\n",
        "#from getpass import getpass\n",
        "#import urllib\n",
        "\n",
        "#cmd = 'git clone https://github.com/joosthub/PyTorchNLPBook.git'\n",
        "#os.system(cmd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWaXMihaoiaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3lhylHKoiaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreTrainedEmbeddings(object):\n",
        "    \"\"\" A wrapper around pre-trained word vectors and their use \"\"\"\n",
        "    def __init__(self, word_to_index, word_vectors):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word_to_index (dict): mapping from word to integers\n",
        "            word_vectors (list of numpy arrays)\n",
        "        \"\"\"\n",
        "        self.word_to_index = word_to_index\n",
        "        self.word_vectors = word_vectors\n",
        "        self.index_to_word = {v: k for k, v in self.word_to_index.items()}\n",
        "\n",
        "        self.index = AnnoyIndex(len(word_vectors[0]), metric='euclidean')\n",
        "        print(\"Building Index!\")\n",
        "        for _, i in self.word_to_index.items():\n",
        "            self.index.add_item(i, self.word_vectors[i])\n",
        "        self.index.build(50)\n",
        "        print(\"Finished!\")\n",
        "        \n",
        "    @classmethod\n",
        "    def from_embeddings_file(cls, embedding_file):\n",
        "        \"\"\"Instantiate from pre-trained vector file.\n",
        "        \n",
        "        Vector file should be of the format:\n",
        "            word0 x0_0 x0_1 x0_2 x0_3 ... x0_N\n",
        "            word1 x1_0 x1_1 x1_2 x1_3 ... x1_N\n",
        "        \n",
        "        Args:\n",
        "            embedding_file (str): location of the file\n",
        "        Returns: \n",
        "            instance of PretrainedEmbeddigns\n",
        "        \"\"\"\n",
        "        word_to_index = {}\n",
        "        word_vectors = []\n",
        "\n",
        "        with open(embedding_file) as fp:\n",
        "            for line in fp.readlines():\n",
        "                line = line.split(\" \")\n",
        "                word = line[0]\n",
        "                vec = np.array([float(x) for x in line[1:]])\n",
        "                \n",
        "                word_to_index[word] = len(word_to_index)\n",
        "                word_vectors.append(vec)\n",
        "                \n",
        "        return cls(word_to_index, word_vectors)\n",
        "    \n",
        "    def get_embedding(self, word):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            word (str)\n",
        "        Returns\n",
        "            an embedding (numpy.ndarray)\n",
        "        \"\"\"\n",
        "        return self.word_vectors[self.word_to_index[word]]\n",
        "\n",
        "    def get_closest_to_vector(self, vector, n=1):\n",
        "        \"\"\"Given a vector, return its n nearest neighbors\n",
        "        \n",
        "        Args:\n",
        "            vector (np.ndarray): should match the size of the vectors \n",
        "                in the Annoy index\n",
        "            n (int): the number of neighbors to return\n",
        "        Returns:\n",
        "            [str, str, ...]: words that are nearest to the given vector. \n",
        "                The words are not ordered by distance \n",
        "        \"\"\"\n",
        "        nn_indices = self.index.get_nns_by_vector(vector, n)\n",
        "        return [self.index_to_word[neighbor] for neighbor in nn_indices]\n",
        "    \n",
        "    def compute_and_print_analogy(self, word1, word2, word3):\n",
        "        \"\"\"Prints the solutions to analogies using word embeddings\n",
        "\n",
        "        Analogies are word1 is to word2 as word3 is to __\n",
        "        This method will print: word1 : word2 :: word3 : word4\n",
        "        \n",
        "        Args:\n",
        "            word1 (str)\n",
        "            word2 (str)\n",
        "            word3 (str)\n",
        "        \"\"\"\n",
        "        vec1 = self.get_embedding(word1)\n",
        "        vec2 = self.get_embedding(word2)\n",
        "        vec3 = self.get_embedding(word3)\n",
        "\n",
        "        # now compute the fourth word's embedding!\n",
        "        spatial_relationship = vec2 - vec1\n",
        "        vec4 = vec3 + spatial_relationship\n",
        "\n",
        "        closest_words = self.get_closest_to_vector(vec4, n=4)\n",
        "        existing_words = set([word1, word2, word3])\n",
        "        closest_words = [word for word in closest_words \n",
        "                             if word not in existing_words] \n",
        "\n",
        "        if len(closest_words) == 0:\n",
        "            print(\"Could not find nearest neighbors for the computed vector!\")\n",
        "            return\n",
        "        \n",
        "        for word4 in closest_words:\n",
        "            print(\"{} : {} :: {} : {}\".format(word1, word2, word3, word4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocmiqct3oiaJ",
        "colab_type": "code",
        "outputId": "7b2217a7-4369-40c5-dbcd-be1c4c00f798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings = PreTrainedEmbeddings.from_embeddings_file('data/glove/glove.6B.100d.txt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Index!\n",
            "Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3wGNNEZoiaM",
        "colab_type": "code",
        "outputId": "fc67c614-160f-4de4-b21e-9374d0b767da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('man', 'he', 'woman')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man : he :: woman : she\n",
            "man : he :: woman : never\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNx1jB-oiaO",
        "colab_type": "code",
        "outputId": "d4d54e52-92c3-4c1a-c191-fbbc8dcefa35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('fly', 'plane', 'sail')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fly : plane :: sail : ship\n",
            "fly : plane :: sail : vessel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgnrbKDoiaQ",
        "colab_type": "code",
        "outputId": "3a5ab2cb-4e2c-4a64-8a47-db582f5c92ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('cat', 'kitten', 'dog')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat : kitten :: dog : puppy\n",
            "cat : kitten :: dog : toddler\n",
            "cat : kitten :: dog : sleds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55oog0dVoiaS",
        "colab_type": "code",
        "outputId": "c152f099-9c12-447d-be5d-a30c5c479a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('blue', 'color', 'dog')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blue : color :: dog : cat\n",
            "blue : color :: dog : animal\n",
            "blue : color :: dog : breed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXwa7Jr6oiaU",
        "colab_type": "code",
        "outputId": "7a8afcc2-5fcd-481d-8ef0-0be5de240204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('leg', 'legs', 'hand')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "leg : legs :: hand : fingers\n",
            "leg : legs :: hand : ears\n",
            "leg : legs :: hand : stick\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6SOG1ZboiaW",
        "colab_type": "code",
        "outputId": "7dad6e1b-8cbb-4360-eabe-8d8fb97e04de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('toe', 'foot', 'finger')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toe : foot :: finger : hand\n",
            "toe : foot :: finger : attached\n",
            "toe : foot :: finger : apart\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxRm5AYMoiaY",
        "colab_type": "code",
        "outputId": "d1f9b5fa-a88d-4f8b-e026-c8e278129d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('talk', 'communicate', 'read')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "talk : communicate :: read : instructions\n",
            "talk : communicate :: read : communicating\n",
            "talk : communicate :: read : transmit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXC90XtKoiaa",
        "colab_type": "code",
        "outputId": "2416034b-af62-4fee-84e5-e46c137193b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('blue', 'democrat', 'red')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blue : democrat :: red : republican\n",
            "blue : democrat :: red : congressman\n",
            "blue : democrat :: red : senator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d4G05Xoiac",
        "colab_type": "code",
        "outputId": "b0db517f-e681-4aca-ec07-70a270cb8460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('man', 'king', 'woman')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man : king :: woman : queen\n",
            "man : king :: woman : monarch\n",
            "man : king :: woman : throne\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEVpskfroiae",
        "colab_type": "code",
        "outputId": "ba779042-fd1e-42a5-a7c5-fa887c28a432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('man', 'doctor', 'woman')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man : doctor :: woman : nurse\n",
            "man : doctor :: woman : physician\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiczV7Ixoiag",
        "colab_type": "code",
        "outputId": "09c87649-bfce-47bf-cc9c-4117232202af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "embeddings.compute_and_print_analogy('fast', 'fastest', 'small')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fast : fastest :: small : smallest\n",
            "fast : fastest :: small : largest\n",
            "fast : fastest :: small : among\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9huX8YynvOaX",
        "colab_type": "code",
        "outputId": "96dce9c0-751a-47ba-8e6f-d44e5cf692dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%cd 5_2_CBOW/data\n",
        "!ls\n",
        "!chmod 777 get-all-data.sh\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW/data\n",
            "ag_news  download.py\t  glove  README.md  yelp\n",
            "books\t get-all-data.sh  nmt\t surnames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGcW5mcCwhjn",
        "colab_type": "code",
        "outputId": "8031fc11-32c8-4dcb-cd87-df9ed142ca95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!mkdir -p glove\n",
        "%cd glove\n",
        "!wget -nc http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -n glove.6B.zip\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_5/5_2_CBOW/data/glove\n",
            "File ‘glove.6B.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  glove.6B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR60DUEpwBlO",
        "colab_type": "code",
        "outputId": "f44cc36b-2f02-4250-8af3-6a8ebcc5040a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/data"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL0OJxG_tmS8",
        "colab_type": "code",
        "outputId": "41303d90-0a01-41f8-8474-243717915266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 26\n",
            "-rwx------ 1 root root 1961 Oct 28 17:57 get-all-data.sh\n",
            "-rw------- 1 root root 1929 Oct 27 20:28 README.md\n",
            "-rw------- 1 root root 1572 Oct 27 20:28 download.py\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 surnames\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 ag_news\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 books\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 nmt\n",
            "drwx------ 2 root root 4096 Oct 27 20:28 yelp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiq9rd1yugb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb8c5339-9313-47e5-e73b-dae22d87369d"
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_1\n",
        "!ls"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_1\n",
            "PyTorch_Basics.ipynb  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfFVLzzL08gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5e2f18c-eda5-4c1e-cb09-07c20ce7ac39"
      },
      "source": [
        "%run PyTorch_Basics.ipynb"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[5.3806e-38, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 1.5134e-43]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.0461,  0.4024, -1.0115],\n",
            "        [ 0.2167, -0.6123,  0.5036]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.7749, 0.8208, 0.2793],\n",
            "        [0.6817, 0.2837, 0.6567]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.]])\n",
            "torch.FloatTensor\n",
            "torch.Size([3, 4])\n",
            "tensor([[5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [2., 4.]])\n",
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.3593, 0.3405, 0.6529],\n",
            "        [0.7856, 0.1288, 0.1537]], dtype=torch.float64)\n",
            "float64\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 1.5385, -0.9757,  1.5769],\n",
            "        [ 0.3840, -0.6039, -0.5240]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 3.0771, -1.9515,  3.1539],\n",
            "        [ 0.7680, -1.2077, -1.0479]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 3.0771, -1.9515,  3.1539],\n",
            "        [ 0.7680, -1.2077, -1.0479]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([6])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([3, 5, 7])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([ 3, 12])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 2])\n",
            "Values: \n",
            "tensor([[0, 1]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "1\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[0, 2],\n",
            "        [3, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [0, 1, 2]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0, 4])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "torch.int64\n",
            "int64\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19]])\n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19]])\n",
            "tensor([[ 0],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [ 6],\n",
            "        [ 7],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [11],\n",
            "        [12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[0, 1, 2, 3]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 4,  6,  8, 10],\n",
            "        [ 8, 10, 12, 14]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [10, 11, 12, 13]])\n",
            "torch.Size([3, 4])\n",
            "torch.Size([3, 1, 4])\n",
            "torch.Size([3, 4])\n",
            "x: \n",
            " tensor([[0.6662, 0.3343, 0.7893, 0.3216],\n",
            "        [0.5247, 0.6688, 0.8436, 0.4265],\n",
            "        [0.9561, 0.0770, 0.4108, 0.0014]])\n",
            "--\n",
            "torch.add(x, x): \n",
            " tensor([[1.3324, 0.6686, 1.5786, 0.6433],\n",
            "        [1.0494, 1.3377, 1.6872, 0.8530],\n",
            "        [1.9123, 0.1540, 0.8216, 0.0028]])\n",
            "--\n",
            "x+x: \n",
            " tensor([[1.3324, 0.6686, 1.5786, 0.6433],\n",
            "        [1.0494, 1.3377, 1.6872, 0.8530],\n",
            "        [1.9123, 0.1540, 0.8216, 0.0028]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 8, 10, 12, 14],\n",
            "        [16, 18, 20, 22]])\n",
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "Summing across rows (dim=0): \n",
            " tensor([12, 15, 18, 21])\n",
            "---\n",
            "Summing across columns (dim=1): \n",
            " tensor([ 6, 22, 38])\n",
            "x: \n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "---\n",
            "x[:2, :2]: \n",
            " tensor([[0, 1],\n",
            "        [3, 4]])\n",
            "---\n",
            "x[0][1]: \n",
            " tensor(1)\n",
            "---\n",
            "Setting [0][1] to be 8\n",
            "tensor([[0, 8, 2],\n",
            "        [3, 4, 5]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 9])\n",
            "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
            "        [6, 7, 8, 6, 7, 8, 6, 7, 8]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 3, 3])\n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]])\n",
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "x.tranpose(1, 0): \n",
            " tensor([[ 0,  4,  8],\n",
            "        [ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11]])\n",
            "x.shape: \n",
            " torch.Size([3, 4, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "-----\n",
            "x.transpose(1, 0).shape: \n",
            " torch.Size([4, 3, 5])\n",
            "x.transpose(1, 0): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [20, 21, 22, 23, 24],\n",
            "         [40, 41, 42, 43, 44]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [45, 46, 47, 48, 49]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [50, 51, 52, 53, 54]],\n",
            "\n",
            "        [[15, 16, 17, 18, 19],\n",
            "         [35, 36, 37, 38, 39],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "x.shape: \n",
            " torch.Size([3, 4, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "-----\n",
            "x.permute(1, 0, 2).shape: \n",
            " torch.Size([4, 3, 5])\n",
            "x.permute(1, 0, 2): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [20, 21, 22, 23, 24],\n",
            "         [40, 41, 42, 43, 44]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [45, 46, 47, 48, 49]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [50, 51, 52, 53, 54]],\n",
            "\n",
            "        [[15, 16, 17, 18, 19],\n",
            "         [35, 36, 37, 38, 39],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[ 3.,  6.],\n",
            "        [12., 24.]])\n",
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]])\n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n",
            "tensor([[ 6., 12.],\n",
            "        [22., 44.],\n",
            "        [38., 76.]])\n",
            "tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
            "x: \n",
            " tensor([[2., 3.]], requires_grad=True)\n",
            "---\n",
            "z = 3*x: \n",
            " tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
            "---\n",
            "loss = z.sum(): \n",
            " tensor(15., grad_fn=<SumBackward0>)\n",
            "---\n",
            "after loss.backward(), x.grad: \n",
            " tensor([[3., 3.]])\n",
            "tensor([0.5403])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_1/PyTorch_Basics.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# this is meant to break!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ql_yub1d5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4460041-f9f4-4218-f638-9c0647982542"
      },
      "source": [
        "%cd /content/drive/My Drive/PyTorchNLPBook/chapters/chapter_3/data\n",
        "!ls"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PyTorchNLPBook/chapters/chapter_3/data\n",
            "download.py  get-all-data.sh  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioRyRp7J1zTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "59b8f971-105e-47d2-9ea9-2021fb7de07c"
      },
      "source": [
        "!chmod 777 get-all-data.sh\n",
        "!ls -lta\n",
        "! ./get-all-data.sh"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 9\n",
            "-rwx------ 1 root root 1961 Oct 29 04:48 get-all-data.sh\n",
            "drwx------ 3 root root 4096 Oct 29 04:47 Drive\n",
            "-rw------- 1 root root 1572 Oct 27 20:28 download.py\n",
            "-rw------- 1 root root  572 Oct 27 20:28 README.md\n",
            "Trying to fetch ./yelp/raw_train.csv\n",
            "12536it [00:04, 3102.43it/s]\n",
            "Trying to fetch ./yelp/raw_test.csv\n",
            "848it [00:00, 4163.28it/s]\n",
            "Trying to fetch ./yelp/reviews_with_splits_lite.csv\n",
            "1217it [00:00, 2608.77it/s]\n",
            "Trying to fetch ./surnames/surnames.csv\n",
            "6it [00:00, 1308.06it/s]\n",
            "Trying to fetch ./surnames/surnames_with_splits.csv\n",
            "8it [00:00, 2333.90it/s]\n",
            "Trying to fetch ./books/frankenstein.txt\n",
            "14it [00:00, 2572.97it/s]\n",
            "Trying to fetch ./books/frankenstein_with_splits.csv\n",
            "109it [00:00, 4994.20it/s]\n",
            "Trying to fetch ./ag_news/news.csv\n",
            "188it [00:01, 158.89it/s]\n",
            "Trying to fetch ./ag_news/news_with_splits.csv\n",
            "208it [00:00, 911.58it/s]\n",
            "Trying to fetch ./nmt/eng-fra.txt\n",
            "292it [00:00, 365.54it/s]\n",
            "Trying to fetch ./nmt/simplest_eng_fra.csv\n",
            "30it [00:00, 2895.69it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd0qmgWr2aFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}